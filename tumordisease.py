# -*- coding: utf-8 -*-
"""TumorDisease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n2G2XdoTqkVlpKqlxwXikdihMfX4EOyA
"""

#import required classes and packages
import os
import cv2
import numpy as np
from keras.utils.np_utils import to_categorical
from keras.layers import  MaxPooling2D
from keras.layers import Dense, Dropout, Activation, Flatten, AveragePooling2D, BatchNormalization
from keras.layers import Convolution2D
from keras.models import Sequential, load_model, Model
import pickle
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
import keras
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.model_selection import GridSearchCV #grid class for tuning each algorithm
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from keras.applications import VGG16

#define and load class labels found in dataset
path = "Dataset"
labels = []
X = []
Y = []
for root, dirs, directory in os.walk(path):
    for j in range(len(directory)):
        name = os.path.basename(root)
        if name not in labels:
            labels.append(name.strip())
print("Brain Tumor Class Labels Found in Dataset: "+str(labels))

#define function to get class label of given image
def getLabel(name):
    index = -1
    for i in range(len(labels)):
        if labels[i] == name:
            index = i
            break
    return index

#load dataset image and process them
if os.path.exists("model/X.txt.npy"):
    X = np.load('model/X.txt.npy')
    Y = np.load('model/Y.txt.npy')
else: #if images not process then read and process image pixels
    for root, dirs, directory in os.walk(path):#connect to dataset folder
        for j in range(len(directory)):#loop all images from dataset folder
            name = os.path.basename(root)
            if 'Thumbs.db' not in directory[j]:
                img = cv2.imread(root+"/"+directory[j])#read images
                img = cv2.resize(img, (32, 32))#resize image
                X.append(img) #add image pixels to X array
                label = getLabel(name)#get image label id
                Y.append(label)#add image label
    X = np.asarray(X)#convert array as numpy array
    Y = np.asarray(Y)
    np.save('model/X.txt',X)#save process images and labels
    np.save('model/Y.txt',Y)
print("Dataset images loaded")
print("Total images found in dataset : "+str(X.shape[0]))
print()

#visualizing class labels count found in dataset
names, count = np.unique(Y, return_counts = True)
height = count
bars = labels
y_pos = np.arange(len(bars))
plt.figure(figsize = (4, 3))
plt.bar(y_pos, height)
plt.xticks(y_pos, bars)
plt.xlabel("Dataset Class Label Graph")
plt.ylabel("Count")
plt.xticks(rotation=90)
plt.show()

#display processed sample image
img = X[0]
plt.figure(figsize =(2, 2))
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title("Sample Processed Image")

#preprocess images like shuffling and normalization
X = X.astype('float32')
X = X/255 #normalized pixel values between 0 and 1
indices = np.arange(X.shape[0])
np.random.shuffle(indices)#shuffle all images
X = X[indices]
Y = Y[indices]
Y = to_categorical(Y)
#split dataset into train and test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
print("Dataset Image Processing & Normalization Completed")
print("80% images used to train algorithms : "+str(X_train.shape[0]))
print("20% image used to train algorithms : "+str(X_test.shape[0]))

#define global variables to save accuracy and other metrics
accuracy = []
precision = []
recall = []
fscore = []

#function to calculate accuracy and other metrics
def calculateMetrics(algorithm, predict, y_test):
    a = accuracy_score(y_test,predict)*100
    p = precision_score(y_test, predict,average='macro') * 100
    r = recall_score(y_test, predict,average='macro') * 100
    f = f1_score(y_test, predict,average='macro') * 100
    accuracy.append(a)
    precision.append(p)
    recall.append(r)
    fscore.append(f)
    print(algorithm+" Accuracy  :  "+str(a))
    print(algorithm+" Precision : "+str(p))
    print(algorithm+" Recall    : "+str(r))
    print(algorithm+" FScore    : "+str(f))
    conf_matrix = confusion_matrix(y_test, predict)
    plt.figure(figsize =(6, 3))
    ax = sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, cmap="viridis" ,fmt ="g");
    ax.set_ylim([0,len(labels)])
    plt.title(algorithm+" Confusion matrix")
    plt.xticks(rotation=90)
    plt.ylabel('True class')
    plt.xlabel('Predicted class')
    plt.show()

#training KNN algorithm with tuning parameters
X_train1 = np.reshape(X_train, (X_train.shape[0], (X_train.shape[1] * X_train.shape[2] * X_train.shape[3])))
X_test1 = np.reshape(X_test, (X_test.shape[0], (X_test.shape[1] * X_test.shape[2] * X_test.shape[3])))
y_test1 = np.argmax(y_test, axis=1)
y_train1 = np.argmax(y_train, axis=1)
X_train1 = X_train1[0:1000]
y_train1 = y_train1[0:1000]
tuning_param = {'n_neighbors' : [2, 3, 5], 'p' : [1]}
knn_cls = GridSearchCV(KNeighborsClassifier(), tuning_param, cv=5)#defining knn with tuned parameters
knn_cls.fit(X_train1, y_train1)#now train KNN with tuning params
predict = knn_cls.predict(X_test1) #perfrom prediction on test data
#call this function to calculate accuracy and other metrics
calculateMetrics("Tuned KNN", predict, y_test1)

#training tuned Random Forest algorithm
tuning_param = {'n_estimators' : [50, 100, 150], 'max_depth': [5, 10, 15]}
rf_cls = GridSearchCV(RandomForestClassifier(), tuning_param, cv=5)#defining Random Forest with tuned parameters
rf_cls.fit(X_train1, y_train1)#now train Random Forest
predict = rf_cls.predict(X_test1) #perfrom prediction on test data
#call this function to calculate accuracy and other metrics
calculateMetrics("Tuned Random Forest", predict, y_test1)

#training tuned SM algorithm
#defining SVM tuning parameters
tuning_param = {'C' : [2, 3, 5], 'kernel': ['linear', 'rbf']}
svm_cls = GridSearchCV(svm.SVC(), tuning_param, cv=5)
svm_cls.fit(X_train1, y_train1)#now train SVM
predict = svm_cls.predict(X_test1) #perfrom prediction on test data
#call this function to calculate accuracy and other metrics
calculateMetrics("Tuned SVM", predict, y_test1)

#training CNN algorithm by usig different layers with tuning values
cnn_model = Sequential()
#defining CNN layer with 32 neurons of size 3 X 3 to filter image features 32 times
cnn_model.add(Convolution2D(32, (3 , 3), input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), activation = 'relu'))
#defining max pool layer to collect filtered relevant features from CNN layer
cnn_model.add(MaxPooling2D(pool_size = (2, 2)))
#defining another CNN layer to further optimized features
cnn_model.add(Convolution2D(32, (3, 3), activation = 'relu'))
#maxpool collect optimized features from CNN
cnn_model.add(MaxPooling2D(pool_size = (2, 2)))
#convert multi dimension features to single dimension features
cnn_model.add(Flatten())
#defining output prediction Dense layer
cnn_model.add(Dense(units = 256, activation = 'relu'))
cnn_model.add(Dense(units = y_train.shape[1], activation = 'softmax'))
#compiling, training and loading model
cnn_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
if os.path.exists("model/cnn_weights.hdf5") == False:
    model_check_point = ModelCheckpoint(filepath='model/cnn_weights.hdf5', verbose = 1, save_best_only = True)
    hist = cnn_model.fit(X_train, y_train, batch_size = 64, epochs = 60, validation_data=(X_test, y_test), callbacks=[model_check_point], verbose=1)
    f = open('model/cnn_history.pckl', 'wb')
    pickle.dump(hist.history, f)
    f.close()
else:
    cnn_model.load_weights("model/cnn_weights.hdf5")
#perform prediction on test data
predict = cnn_model.predict(X_test)
predict = np.argmax(predict, axis=1)
y_test1 = np.argmax(y_test, axis=1)
#call this function to calculate accuracy and other metrics
calculateMetrics("Tuned CNN", predict, y_test1)

#initializing pretrained VGG16 algorithm
vgg16 = VGG16(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), include_top=False, weights='imagenet')
for layer in vgg16.layers:
    layer.trainable = False
#now utilizing VGG16 as transfer learning to predict eye diseases
baseModel = vgg16.output
baseModel = AveragePooling2D(pool_size=(1, 1))(baseModel)
baseModel = Flatten(name="flatten")(baseModel)
baseModel = Dense(256, activation="relu")(baseModel)
baseModel = Dropout(0.5)(baseModel)
baseModel = Dense(y_train.shape[1], activation="softmax")(baseModel)
vgg16_model = Model(inputs=vgg16.input, outputs=baseModel)
vgg16_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
#densenet_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
if os.path.exists("model/vgg_weights.hdf5") == False:
    model_check_point = ModelCheckpoint(filepath='model/vgg_weights.hdf5', verbose = 1, save_best_only = True)
    hist = vgg16_model.fit(X_train, y_train, batch_size = 64, epochs = 60, validation_data=(X_test, y_test), callbacks=[model_check_point], verbose=1)
    f = open('model/vgg_history.pckl', 'wb')
    pickle.dump(hist.history, f)
    f.close()
else:
    vgg16_model.load_weights("model/vgg_weights.hdf5")
#perform prediction on test images
predict = vgg16_model.predict(X_test)
predict = np.argmax(predict, axis=1)
y_test1 = np.argmax(y_test, axis=1)
#call this function to calculate accuracy and other metrics
calculateMetrics("Pretrained VGG-16", predict, y_test1)

#plot all algorithm performance in tabukar format
import pandas as pd
df = pd.DataFrame([['KNN','Accuracy',accuracy[0]],['KNN','Precision',precision[0]],['KNN','Recall',recall[0]],['KNN','FSCORE',fscore[0]],
                   ['Random Forest','Accuracy',accuracy[1]],['Random Forest','Precision',precision[1]],['Random Forest','Recall',recall[1]],['Random Forest','FSCORE',fscore[1]],
                   ['SVM','Accuracy',accuracy[2]],['SVM','Precision',precision[2]],['SVM','Recall',recall[2]],['SVM','FSCORE',fscore[2]],
                   ['CNN2D','Accuracy',accuracy[3]],['CNN2D','Precision',precision[3]],['CNN2D','Recall',recall[3]],['CNN2D','FSCORE',fscore[3]],
                   ['Pre-Trained VGG16','Accuracy',accuracy[4]],['Pre-Trained VGG16','Precision',precision[4]],['Pre-Trained VGG16','Recall',recall[4]],['Pre-Trained VGG16','FSCORE',fscore[4]],
                  ],columns=['Parameters','Algorithms','Value'])
df.pivot("Parameters", "Algorithms", "Value").plot(kind='bar', figsize=(6, 3))
plt.title("All Algorithms Performance Graph")
plt.show()

#display all algorithm performnace
algorithms = ['Tuned KNN', 'Tuned Random Forest', 'Tuned SVM', 'Tuned CNN', 'Pre-Trained VGG16']
data = []
for i in range(len(accuracy)):
    data.append([algorithms[i], accuracy[i], precision[i], recall[i], fscore[i]])
data = pd.DataFrame(data, columns=['Algorithm Name', 'Accuracy', 'Precision', 'Recall', 'FSCORE'])
data

#use this function to predict fish species uisng extension model
def predict(image_path):

    image = cv2.imread(image_path)

    if image is None:
        print("‚ùå Image not found:", image_path)
        return

    img = cv2.resize(image, (32,32))
    im2arr = np.array(img)
    im2arr = im2arr.reshape(1,32,32,3)

    img = im2arr.astype('float32')
    img = img / 255.0

    pred = cnn_model.predict(img)
    pred = np.argmax(pred)

    img2 = cv2.imread(image_path)
    img2 = cv2.resize(img2, (700,400))
    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)

    cv2.putText(
        img2,
        'Predicted As : ' + labels[pred],
        (10, 75),
        cv2.FONT_HERSHEY_SIMPLEX,
        1.4,
        (0, 255, 0),
        2
    )

    plt.figure(figsize=(8,3))
    plt.imshow(img2)
    plt.axis("off")
    plt.show()
    
#call this function to predict pupillometry disease with test image path
predict("testImages/00.jpg")

#call this function to predict pupillometry disease with test image path
predict("testImages/0.jpg")

#call this function to predict pupillometry disease with test image path
predict("testImages/1.jpg")

#call this function to predict pupillometry disease with test image path
predict("testImages/3.jpg")

